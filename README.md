# interns-grup-b
CNN(Convolutional Neural Network)
CNN NEDÄ°R?:
CNN, Ã¶zellikle gÃ¶rÃ¼ntÃ¼ iÅŸleme ve bilgisayarla gÃ¶rme (computer vision) problemlerinde Ã§ok baÅŸarÄ±lÄ± olan bir yapay sinir aÄŸÄ± mimarisidir
 
En basit ÅŸekilde bir CNN modeli gÃ¶rseldeki gibi Ã¶zetlenebilir. Bir giriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼ (Input), evriÅŸim katmanÄ± (CONV), ortaklama (pooling) ve tam baÄŸlantÄ± (fully connected â€” FC) katmanlarÄ±ndan (layers) oluÅŸur. Åimdide bu katmanlarÄ± inceleyelim.
1-)Convolution (evriÅŸim katmanÄ±)
GÃ¶rÃ¼ntÃ¼den Ã¶zellik Ã§Ä±karÄ±r. Kernel (filtre) ile gÃ¶rÃ¼ntÃ¼ Ã¼zerinde kayan pencere yÃ¶ntemi uygulanÄ±r.
 
S(i,j)=mâˆ‘nâˆ‘I(i+m,j+n)â‹…K(m,n)
 CNNâ€™de tamamen rastgele filtreler Ã¼retiyoruz, bu rastgele Ã¼rettiÄŸimiz filtreleri resmimize uygulayarak resmin belirli bÃ¶lgelerinden Ã¶zellik Ã§Ä±karÄ±mÄ± yapmaya Ã§alÄ±ÅŸÄ±yoruz.


1 2 3 0 1  
0 1 2 3 1         
3 1 0 2 2       5*5 lik gÃ¶rÃ¼ntÃ¼mÃ¼z 
1 2 1 0 0  
0 1 3 1 2

0 1 0  
1 -4 1    3*3 lÃ¼k filtremiz
0 1 0

1 2 3  
0 1 2     sadece 1 bÃ¶lgeye uygulanan filtrelememiz 
3 1 0
S(i,j)=(0â‹…1)+(1â‹…2)+(0â‹…3)+(1â‹…0)+(âˆ’4â‹…1)+(1â‹…2)+(0â‹…3)+(1â‹…1)+(0â‹…0)=2âˆ’4+2+1=1 bu formÃ¼l ile bulunuyor

 


2-)Ortaklama (POOLÄ°NG): Pooling, belirli bir boyutta pencere ile gÃ¶rÃ¼ntÃ¼ veya feature map Ã¼zerinde gezinerek, o pencere iÃ§indeki deÄŸeri bir Ã¶zet deÄŸere indirger.
Pooling tÃ¼rleri
Max Pooling	Pencere iÃ§indeki en bÃ¼yÃ¼k deÄŸeri alÄ±r. En yaygÄ±n olanÄ±dÄ±r.
Average Pooling	Pencere iÃ§indeki ortalama deÄŸeri alÄ±r.
Min Pooling (nadir)	En kÃ¼Ã§Ã¼k deÄŸeri alÄ±r.
Y(i,j)=0â‰¤m<fmax0â‰¤n<fmaxX(iâ‹…s+m,jâ‹…s+n)
  Girdi matris 
  MAX POOLÄ°NG 
 
â€¢	3-) Tam BaÄŸlantÄ± (Fully-Connected â€” FC):
Her nÃ¶ron, Ã¶nceki katmandaki tÃ¼m nÃ¶ronlara baÄŸlÄ±dÄ±r.
CNNâ€™de:
â€¢	Conv ve pooling katmanlarÄ± Ã¶zellikleri Ã§Ä±karÄ±r.
â€¢	FC katmanÄ± bu Ã¶zellikleri alÄ±r ve sÄ±nÄ±flandÄ±rma, regresyon, karar verme gibi son Ã§Ä±ktÄ±yÄ± Ã¼retir.
z=w1x1+w2x2+â‹¯+wnxn+b=wTâ‹…x+b

Diyelim Conv + Pooling sonucu ÅŸu vektÃ¶r Ã§Ä±ktÄ±:
x=[0.2, 0.5, 0.1]\mathbf{x} = [0.2,\ 0.5,\ 0.1]x=[0.2, 0.5, 0.1] 
Ve FC katman aÄŸÄ±rlÄ±klarÄ±:
w=[0.3, âˆ’0.7, 0.5],b=0.2\mathbf{w} = [0.3,\ -0.7,\ 0.5],\quad b = 0.2w=[0.3, âˆ’0.7, 0.5],b=0.2 
SonuÃ§:
z=0.3â‹…0.2+(âˆ’0.7)â‹…0.5+0.5â‹…0.1+0.2=0.06âˆ’0.35+0.05+0.2=âˆ’0.04z = 0.3\cdot0.2 + (-0.7)\cdot0.5 + 0.5\cdot0.1 + 0.2 = 0.06 - 0.35 + 0.05 + 0.2 = -0.04z=0.3â‹…0.2+(âˆ’0.7)â‹…0.5+0.5â‹…0.1+0.2=0.06âˆ’0.35+0.05+0.2=âˆ’0.04 
Aktivasyon fonksiyonu (Ã¶rnek: ReLU):
a=maxâ¡(0,âˆ’0.04)=0a = \max(0, -0.04) = 0a=max(0,âˆ’0.04)=0
 
4-) Activation:
Aktivasyon fonksiyonu, nÃ¶ronun aÄŸÄ±rlÄ±klÄ± giriÅŸlerinin toplamÄ±nÄ± alÄ±r ve Ã§Ä±ktÄ±nÄ±n aktif mi pasif mi olacaÄŸÄ±na karar verir.
z=wTâ‹…x+b
BirkaÃ§ tane yaygÄ±n activation fonksiyonu var 
ğŸ”¹ ReLU (Rectified Linear Unit)
Negatif giriÅŸleri sÄ±fÄ±ra indirgerken, pozitif deÄŸerleri olduÄŸu gibi geÃ§irir.
Bu sayede hesaplamalar daha hÄ±zlÄ± olur ve Ã¶ÄŸrenme sÃ¼reci verimli ilerler.
FormÃ¼l:
f(x)=maxâ¡(0,x)f(x) = \max(0, x)f(x)=max(0,x) 
________________________________________
ğŸ”¹ Sigmoid
Girdiyi 0 ile 1 arasÄ±ndaki bir deÄŸere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
Ã–zellikle iki sÄ±nÄ±flÄ± (binary) sÄ±nÄ±flandÄ±rma problemlerinde kullanÄ±lÄ±r.
FormÃ¼l:
f(x)=11+eâˆ’xf(x) = \frac{1}{1 + e^{-x}}f(x)=1+eâˆ’x1 
________________________________________
ğŸ”¹ Tanh (Hiperbolik Tanjant)
Girdiyi -1 ile 1 arasÄ±na Ã§eker. Sigmoidâ€™e gÃ¶re daha dengeli Ã§Ä±ktÄ±lar Ã¼retir, Ã§Ã¼nkÃ¼ ortalamasÄ± sÄ±fÄ±ra yakÄ±ndÄ±r.
Bu da Ã¶zellikle negatif/pozitif verilerle Ã§alÄ±ÅŸÄ±rken avantaj saÄŸlar.
FormÃ¼l:
f(x)=exâˆ’eâˆ’xex+eâˆ’xf(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}f(x)=ex+eâˆ’xexâˆ’eâˆ’x 
1. Classification (SÄ±nÄ±flandÄ±rma):
GÃ¶rÃ¼ntÃ¼nÃ¼n tamamÄ±na bakarak tek bir sÄ±nÄ±f etiketi atama iÅŸlemidir.
Ã–rn: â€œBu bir kedi mi, kÃ¶pek mi, araba mÄ±?â€ gibi sorularÄ± yanÄ±tlar.
2. Detection (Nesne Tespiti)
Bir gÃ¶rÃ¼ntÃ¼de birden fazla nesne varsa, bunlarÄ± etiketleyerek konumlarÄ±nÄ± (kutu iÃ§inde) tespit eder.
Nerede ve ne var?â€ sorusunu yanÄ±tlar.
3. Segmentation (GÃ¶rÃ¼ntÃ¼ Segmentasyonu)
GÃ¶rÃ¼ntÃ¼deki her bir pikselin hangi nesneye ait olduÄŸunu belirler.
En ayrÄ±ntÄ±lÄ± gÃ¶revdir. "Ne var ve tam olarak neresinde?"
